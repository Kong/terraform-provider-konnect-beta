// Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT.

package shared

import (
	"encoding/json"
	"fmt"
)

type LLMMetrics string

const (
	LLMMetricsTotalTokens                      LLMMetrics = "total_tokens"
	LLMMetricsPromptTokens                     LLMMetrics = "prompt_tokens"
	LLMMetricsCompletionTokens                 LLMMetrics = "completion_tokens"
	LLMMetricsAiRequestCount                   LLMMetrics = "ai_request_count"
	LLMMetricsCost                             LLMMetrics = "cost"
	LLMMetricsLlmCacheEmbeddingsLatencyAverage LLMMetrics = "llm_cache_embeddings_latency_average"
	LLMMetricsLlmCacheFetchLatencyAverage      LLMMetrics = "llm_cache_fetch_latency_average"
	LLMMetricsLlmLatencyAverage                LLMMetrics = "llm_latency_average"
	LLMMetricsLlmEmbeddingsTokens              LLMMetrics = "llm_embeddings_tokens"
	LLMMetricsLlmEmbeddingsCost                LLMMetrics = "llm_embeddings_cost"
)

func (e LLMMetrics) ToPointer() *LLMMetrics {
	return &e
}
func (e *LLMMetrics) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "total_tokens":
		fallthrough
	case "prompt_tokens":
		fallthrough
	case "completion_tokens":
		fallthrough
	case "ai_request_count":
		fallthrough
	case "cost":
		fallthrough
	case "llm_cache_embeddings_latency_average":
		fallthrough
	case "llm_cache_fetch_latency_average":
		fallthrough
	case "llm_latency_average":
		fallthrough
	case "llm_embeddings_tokens":
		fallthrough
	case "llm_embeddings_cost":
		*e = LLMMetrics(v)
		return nil
	default:
		return fmt.Errorf("invalid value for LLMMetrics: %v", v)
	}
}
